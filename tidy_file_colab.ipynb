{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pau-torrente/capstone-project/blob/pau/tidy_file_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sOZGnPX674P",
        "outputId": "145670a7-e9ed-408e-90d4-45c38cfe2721"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "T5WnTh7r6e2-",
        "outputId": "fa138de6-4a14-4a93-dcea-1e12d302d459"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>station_id</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>ctx-4</th>\n",
              "      <th>ctx-3</th>\n",
              "      <th>ctx-2</th>\n",
              "      <th>ctx-1</th>\n",
              "      <th>percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>41.437338</td>\n",
              "      <td>2.174096</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.504902</td>\n",
              "      <td>0.751131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>271.0</td>\n",
              "      <td>41.450608</td>\n",
              "      <td>2.192363</td>\n",
              "      <td>2022.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.753968</td>\n",
              "      <td>0.659341</td>\n",
              "      <td>0.645022</td>\n",
              "      <td>0.686508</td>\n",
              "      <td>0.769231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>149.0</td>\n",
              "      <td>41.395868</td>\n",
              "      <td>2.192952</td>\n",
              "      <td>2022.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.491582</td>\n",
              "      <td>0.675214</td>\n",
              "      <td>0.864198</td>\n",
              "      <td>0.801347</td>\n",
              "      <td>0.735043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>342.0</td>\n",
              "      <td>41.403497</td>\n",
              "      <td>2.193658</td>\n",
              "      <td>2020.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.898990</td>\n",
              "      <td>0.831909</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>358.0</td>\n",
              "      <td>41.387244</td>\n",
              "      <td>2.179304</td>\n",
              "      <td>2021.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.513333</td>\n",
              "      <td>0.766667</td>\n",
              "      <td>0.943333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  station_id        lat       lon    year  month   day  hour  \\\n",
              "0      0       290.0  41.437338  2.174096  2019.0    7.0  22.0   8.0   \n",
              "1      1       271.0  41.450608  2.192363  2022.0    6.0  10.0  21.0   \n",
              "2      2       149.0  41.395868  2.192952  2022.0    6.0   8.0  20.0   \n",
              "3      3       342.0  41.403497  2.193658  2020.0    2.0   4.0   4.0   \n",
              "4      4       358.0  41.387244  2.179304  2021.0    5.0  28.0   8.0   \n",
              "\n",
              "      ctx-4     ctx-3     ctx-2     ctx-1  percentage  \n",
              "0  0.352941  0.352941  0.352941  0.504902    0.751131  \n",
              "1  0.753968  0.659341  0.645022  0.686508    0.769231  \n",
              "2  0.491582  0.675214  0.864198  0.801347    0.735043  \n",
              "3  0.898990  0.831909  0.777778  0.777778    0.777778  \n",
              "4  0.480000  0.480000  0.513333  0.766667    0.943333  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, FunctionTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "# station_dataframe = dd.read_csv('/content/drive/MyDrive/CapstoneProject/data_bicing_joined_HX.csv', assume_missing=True, delimiter=';')\n",
        "\n",
        "# weather_dataframe = dd.read_csv('/content/drive/MyDrive/CapstoneProject/weather.csv', assume_missing=True, delimiter=',')\n",
        "\n",
        "station_dataframe = dd.read_csv('data/data_bicing_joined_HX.csv', assume_missing=True, delimiter=';')\n",
        "\n",
        "weather_dataframe = dd.read_csv('weather_data/weather.csv', assume_missing=True, delimiter=',')\n",
        "\n",
        "station_dataframe = station_dataframe.loc[station_dataframe['status'] == 'IN_SERVICE']\n",
        "\n",
        "bare_df = station_dataframe[['station_id', 'lat', 'lon', 'year', 'month', 'day', 'hour', '% Docks Availlable',  '% Docks Available H-4','% Docks Available H-3', '% Docks Available H-2', '% Docks Available H-1']]\n",
        "bare_df = bare_df.rename(columns={'% Docks Availlable': 'percentage'})\n",
        "for i in range(1, 5):\n",
        "    bare_df = bare_df.rename(columns={f'% Docks Available H-{i}': f'ctx-{i}'})\n",
        "\n",
        "# Print the head of the updated DataFrame\n",
        "\n",
        "bare_df['index'] = bare_df.index\n",
        "bare_df = bare_df[['index', 'station_id', 'lat', 'lon', 'year', 'month', 'day', 'hour', 'ctx-4', 'ctx-3', 'ctx-2',\t'ctx-1', 'percentage']]\n",
        "\n",
        "bare_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KfFdtx8C6e3A",
        "outputId": "27574b12-1463-42ae-a26b-fbb970ed81e4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>station_id</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>ctx-4</th>\n",
              "      <th>ctx-3</th>\n",
              "      <th>ctx-2</th>\n",
              "      <th>ctx-1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>394</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>0.753086</td>\n",
              "      <td>0.780864</td>\n",
              "      <td>0.799383</td>\n",
              "      <td>0.824074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>337</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>0.463768</td>\n",
              "      <td>0.536232</td>\n",
              "      <td>0.532609</td>\n",
              "      <td>0.601449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>368</td>\n",
              "      <td>3</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>0.787037</td>\n",
              "      <td>0.709877</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>0.601852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>327</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>15</td>\n",
              "      <td>0.753472</td>\n",
              "      <td>0.809028</td>\n",
              "      <td>0.819444</td>\n",
              "      <td>0.736111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>328</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>0.861111</td>\n",
              "      <td>0.802469</td>\n",
              "      <td>0.814815</td>\n",
              "      <td>0.827160</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  station_id  month  day  hour     ctx-4     ctx-3     ctx-2     ctx-1\n",
              "0      0         394      3    7     8  0.753086  0.780864  0.799383  0.824074\n",
              "1      1         337      3   23    12  0.463768  0.536232  0.532609  0.601449\n",
              "2      2         368      3   31     1  0.787037  0.709877  0.611111  0.601852\n",
              "3      3         327      3   23    15  0.753472  0.809028  0.819444  0.736111\n",
              "4      4         328      3    4    20  0.861111  0.802469  0.814815  0.827160"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# data_2_predict = pd.read_csv('/content/drive/MyDrive/CapstoneProject/metadata_sample_submission.csv', delimiter=',')\n",
        "\n",
        "data_2_predict = pd.read_csv('data/metadata_sample_submission.csv', delimiter=',')\n",
        "data_2_predict.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "february2023_info = pd.read_csv('data/2023_02_Febrer_BicingNou_INFORMACIO.csv', delimiter=',')\n",
        "\n",
        "final_loc = february2023_info.drop_duplicates(subset=['station_id'], keep='last')[['station_id', 'lat', 'lon']]\n",
        "\n",
        "# february2023_info = pd.read_csv('/content/drive/MyDrive/CapstoneProject/march2023_info.cÇsv', delimiter=';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>station_id</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1048556</th>\n",
              "      <td>500</td>\n",
              "      <td>41.411957</td>\n",
              "      <td>2.144752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3821777</th>\n",
              "      <td>520</td>\n",
              "      <td>41.386220</td>\n",
              "      <td>9.150292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3853425</th>\n",
              "      <td>494</td>\n",
              "      <td>41.389697</td>\n",
              "      <td>2.165220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4044289</th>\n",
              "      <td>21</td>\n",
              "      <td>41.410844</td>\n",
              "      <td>2.174057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4049296</th>\n",
              "      <td>515</td>\n",
              "      <td>41.435207</td>\n",
              "      <td>2.194800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         station_id        lat       lon\n",
              "1048556         500  41.411957  2.144752\n",
              "3821777         520  41.386220  9.150292\n",
              "3853425         494  41.389697  2.165220\n",
              "4044289          21  41.410844  2.174057\n",
              "4049296         515  41.435207  2.194800"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_loc.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwMdMOy56e3B",
        "outputId": "ecf83916-f3a0-476b-cc05-54ddd0cc77c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14877478"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(bare_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PXB6nqJy6e3B"
      },
      "outputs": [],
      "source": [
        "def weather_prep(weather_df:dd) -> dd:\n",
        "    \n",
        "    weather = weather_df.copy()\n",
        "\n",
        "    weather = weather.groupby(weather.index//2).mean()\n",
        "    \n",
        "    weather['mm_precip'] = weather['mm_precip']*2\n",
        "    weather['timestamp'] = (weather['timestamp']-900).astype(int)\n",
        "    weather['datetime'] = weather['timestamp'].map(lambda x: pd.to_datetime(x, unit='s'))\n",
        "\n",
        "    \n",
        "    weather['timestamp'] = weather['timestamp'].astype(int)\n",
        "\n",
        "    weather['datetime'] = weather['timestamp'].map(lambda x: pd.to_datetime(x, unit='s'))\n",
        "    \n",
        "    return weather\n",
        "\n",
        "def weather_merge(weather_df:dd, station_data:dd) -> dd:\n",
        "    weather = weather_df.copy()\n",
        "    stations = station_data.copy()\n",
        "    if 'year' not in stations.columns:\n",
        "        stations['year'] = 2023\n",
        "\n",
        "    stations[['year', 'month', 'day', 'hour']] = stations[['year', 'month', 'day', 'hour']].astype(int)\n",
        "\n",
        "    stations['datetime'] = dd.to_datetime(stations['year'].astype(str) + '-' +\n",
        "                                                stations['month'].astype(str) + '-' +\n",
        "                                                stations['day'].astype(str) + ' ' +\n",
        "                                                stations['hour'].astype(str) + ':00:00')\n",
        "    \n",
        "    stations = dd.merge(left=stations, right=weather[['datetime', 'temperature','mm_precip']], left_on='datetime', right_on='datetime', how='left')\n",
        "\n",
        "    for i in range(1,5):\n",
        "        df_weather_shifted = weather.copy()\n",
        "        df_weather_shifted['datetime'] = df_weather_shifted['datetime'] + pd.Timedelta(hours=-i)\n",
        "        stations = stations.merge(df_weather_shifted[['datetime', 'temperature','mm_precip']], on='datetime', how='inner', suffixes=('', f'-{abs(i)}'))\n",
        "\n",
        "    return stations\n",
        "\n",
        "class weather_merge_transformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, weather_df:dd, merging_function:callable=weather_merge):\n",
        "        self.weather_df = weather_df\n",
        "        self.func = merging_function\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return self.func(self.weather_df, X)\n",
        "\n",
        "\n",
        "def extra_time_info(df:dd) -> dd:\n",
        "\n",
        "    def is_weekend(day_of_week):\n",
        "        return 1 if day_of_week >= 5 else 0\n",
        "\n",
        "    df['is_weekend'] = df['datetime'].dt.dayofweek.map(is_weekend, meta=('is_weekend', 'int64'))\n",
        "\n",
        "    df['timeframe1'] = df['datetime'].dt.hour.map(lambda x: 1 if x <= 4 else 0, meta=('timeframe1', 'int64'))\n",
        "    df['timeframe2'] = df['datetime'].dt.hour.map(lambda x: 1 if x >= 5 and x <=9 else 0, meta=('timeframe1', 'int64'))\n",
        "    df['timeframe3'] = df['datetime'].dt.hour.map(lambda x: 1 if x >= 10 and x <=14 else 0, meta=('timeframe1', 'int64'))\n",
        "    df['timeframe4'] = df['datetime'].dt.hour.map(lambda x: 1 if x >= 15 and x <=19 else 0, meta=('timeframe1', 'int64'))\n",
        "    df['timeframe5'] = df['datetime'].dt.hour.map(lambda x: 1 if x >= 20 else 0, meta=('timeframe1', 'int64'))\n",
        "\n",
        "    df = df.drop(['datetime'], axis = 1)\n",
        "    \n",
        "    return df\n",
        "\n",
        "\n",
        "def station_loc(id_lat_lon:dd, df:dd) -> dd: #this should be applied for the 2023 march dataset to predict from station_id-location paris from february 2023\n",
        "\n",
        "    assert all(item in list(id_lat_lon.columns) for item in ['station_id', 'lat', 'lon']), 'id_lat_lon must contain station_id, lat and lon columns'\n",
        "    id_locator = id_lat_lon.copy()\n",
        "    data = df.copy()\n",
        "    id_locator = id_locator.drop_duplicates(subset=['station_id'])\n",
        "\n",
        "    data = data.merge(id_locator[['station_id', 'lat', 'lon']], on='station_id', how='left')\n",
        "\n",
        "    return data\n",
        "\n",
        "class station_loc_transformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, id_lat_lon:dd, merging_function:callable=station_loc):\n",
        "        self.id_lat_lon = id_lat_lon\n",
        "        self.func = merging_function\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        return self.func(self.id_lat_lon, X)\n",
        "    \n",
        "def hour_selector(df:dd, hour_list:list) -> dd:\n",
        "    data = df.copy()\n",
        "    data = data.loc[data['hour'].isin(hour_list)]\n",
        "    return data\n",
        "\n",
        "class hour_selector_transformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, hour_list:list):\n",
        "        self.hour_list = hour_list\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        return hour_selector(X, self.hour_list)\n",
        "\n",
        "def time_norm(df:dd, columns:list) -> dd:\n",
        "    \n",
        "        data = df.copy()\n",
        "        for col in columns:\n",
        "            data['cos_'+col] = np.cos(2*np.pi*data[col]/data[col].max())\n",
        "            data['sin_'+col] = np.sin(2*np.pi*data[col]/data[col].max())\n",
        "            data = data.drop([col], axis=1)\n",
        "\n",
        "        data['year_normed'] = (data['year']-2019)/(data['year'].max()-data['year'].min())\n",
        "        data = data.drop(['year'], axis = 1)\n",
        "        \n",
        "        return data\n",
        "\n",
        "class time_norm_transformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, columns:list, norm_function:callable=time_norm):\n",
        "        self.columns = columns\n",
        "        self.func = norm_function\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        return self.func(X, self.columns)\n",
        "    \n",
        "class station_id_dropper(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        return X.drop(['station_id'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "_8l_pNkx6e3C",
        "outputId": "3ccbd2e0-c6e7-49b5-bca1-b30208730bae"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "|    |   index |     lat |     lon |    ctx-4 |     ctx-3 |    ctx-2 |    ctx-1 |   percentage |   temperature |   mm_precip |   temperature-1 |   mm_precip-1 |   temperature-2 |   mm_precip-2 |   temperature-3 |   mm_precip-3 |   temperature-4 |   mm_precip-4 |   is_weekend |   timeframe1 |   timeframe2 |   timeframe3 |   timeframe4 |   timeframe5 |   cos_month |   sin_month |   cos_day |   sin_day |   cos_hour |   sin_hour |   year_normed |\n",
              "|---:|--------:|--------:|--------:|---------:|----------:|---------:|---------:|-------------:|--------------:|------------:|----------------:|--------------:|----------------:|--------------:|----------------:|--------------:|----------------:|--------------:|-------------:|-------------:|-------------:|-------------:|-------------:|-------------:|------------:|------------:|----------:|----------:|-----------:|-----------:|--------------:|\n",
              "| 19 |       3 | 41.4035 | 2.19366 | 0.89899  | 0.831909  | 0.777778 | 0.777778 |     0.777778 |         16.65 |           0 |            15.4 |             0 |            14.6 |             0 |           14.35 |             0 |            15.7 |             0 |            0 |            1 |            0 |            0 |            0 |            0 |         0.5 |    0.866025 |  0.688967 |  0.724793 |   0.460065 |   0.887885 |      0.333333 |\n",
              "| 20 |    7560 | 41.3958 | 2.17871 | 0        | 0.0384615 | 0.03125  | 0.03125  |     0.03125  |         16.65 |           0 |            15.4 |             0 |            14.6 |             0 |           14.35 |             0 |            15.7 |             0 |            0 |            1 |            0 |            0 |            0 |            0 |         0.5 |    0.866025 |  0.688967 |  0.724793 |   0.460065 |   0.887885 |      0.333333 |\n",
              "| 21 |   53954 | 41.3653 | 2.13314 | 0.502841 | 0.454327  | 0.4375   | 0.619792 |     0.71875  |         16.65 |           0 |            15.4 |             0 |            14.6 |             0 |           14.35 |             0 |            15.7 |             0 |            0 |            1 |            0 |            0 |            0 |            0 |         0.5 |    0.866025 |  0.688967 |  0.724793 |   0.460065 |   0.887885 |      0.333333 |\n",
              "| 22 |   70278 | 41.3756 | 2.1439  | 0.465035 | 0.41716   | 0.384615 | 0.384615 |     0.349359 |         16.65 |           0 |            15.4 |             0 |            14.6 |             0 |           14.35 |             0 |            15.7 |             0 |            0 |            1 |            0 |            0 |            0 |            0 |         0.5 |    0.866025 |  0.688967 |  0.724793 |   0.460065 |   0.887885 |      0.333333 |\n",
              "| 23 |  162377 | 41.3875 | 2.12371 | 0.851852 | 0.851852  | 0.851852 | 0.851852 |     0.851852 |         16.65 |           0 |            15.4 |             0 |            14.6 |             0 |           14.35 |             0 |            15.7 |             0 |            0 |            1 |            0 |            0 |            0 |            0 |         0.5 |    0.866025 |  0.688967 |  0.724793 |   0.460065 |   0.887885 |      0.333333 |"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weather_prepped = weather_prep(weather_dataframe)\n",
        "\n",
        "# data_prepared = weather_merge(weather_prepped, bare_df)\n",
        "\n",
        "# data_prepared = extra_time_info(data_prepared)\n",
        "\n",
        "# data_prepared = data_prepared[data_prepared['hour'].isin([4, 9, 14, 19, 23])]\n",
        "\n",
        "# data_prepared = time_norm(df = data_prepared, columns = ['month', 'day', 'hour'])\n",
        "\n",
        "# data_prepared = data_prepared.drop(['station_id'], axis = 1)\n",
        "\n",
        "traintest_preparator = Pipeline([\n",
        "    ('weather_merge', weather_merge_transformer(weather_df=weather_prepped)),  # weather_merge transformer already includes the creation of the datetime column\n",
        "    ('extra_time_info', FunctionTransformer(func=extra_time_info)),\n",
        "    ('hour_selector', hour_selector_transformer(hour_list=[4, 9, 14, 19, 23])),\n",
        "    ('time_normalization', time_norm_transformer(columns=['month', 'day', 'hour'])),\n",
        "    ('station_id_dropper', station_id_dropper())\n",
        "])\n",
        "\n",
        "data_prepared = traintest_preparator.fit_transform(bare_df)\n",
        "\n",
        "Markdown(data_prepared.head().to_markdown())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "|    |   index |    ctx-4 |    ctx-3 |    ctx-2 |    ctx-1 |   temperature |   mm_precip |   temperature-1 |   mm_precip-1 |   temperature-2 |   mm_precip-2 |   temperature-3 |   mm_precip-3 |   temperature-4 |   mm_precip-4 |   is_weekend |   timeframe1 |   timeframe2 |   timeframe3 |   timeframe4 |   timeframe5 |   cos_month |    sin_month |   cos_day |   sin_day |   cos_hour |   sin_hour |   year_normed |     lat |     lon |\n",
              "|---:|--------:|---------:|---------:|---------:|---------:|--------------:|------------:|----------------:|--------------:|----------------:|--------------:|----------------:|--------------:|----------------:|--------------:|-------------:|-------------:|-------------:|-------------:|-------------:|-------------:|------------:|-------------:|----------:|----------:|-----------:|-----------:|--------------:|--------:|--------:|\n",
              "|  0 |       0 | 0.753086 | 0.780864 | 0.799383 | 0.824074 |         14.35 |           0 |            15.3 |             0 |           16.85 |             0 |           15.75 |             0 |            17.2 |             0 |            0 |            0 |            1 |            0 |            0 |            0 |           1 | -2.44929e-16 |  0.151428 |  0.988468 |   -0.57668 |    0.81697 |           inf | 41.3873 | 2.16313 |\n",
              "|  1 |     151 | 0.62963  | 0.669753 | 0.75     | 0.910494 |         14.35 |           0 |            15.3 |             0 |           16.85 |             0 |           15.75 |             0 |            17.2 |             0 |            0 |            0 |            1 |            0 |            0 |            0 |           1 | -2.44929e-16 |  0.151428 |  0.988468 |   -0.57668 |    0.81697 |           inf | 41.4182 | 2.1904  |\n",
              "|  2 |     190 | 1        | 1        | 0.962963 | 0.564815 |         14.35 |           0 |            15.3 |             0 |           16.85 |             0 |           15.75 |             0 |            17.2 |             0 |            0 |            0 |            1 |            0 |            0 |            0 |           1 | -2.44929e-16 |  0.151428 |  0.988468 |   -0.57668 |    0.81697 |           inf | 41.3874 | 2.18754 |\n",
              "|  3 |     369 | 0.814815 | 0.854938 | 0.938272 | 0.728395 |         14.35 |           0 |            15.3 |             0 |           16.85 |             0 |           15.75 |             0 |            17.2 |             0 |            0 |            0 |            1 |            0 |            0 |            0 |           1 | -2.44929e-16 |  0.151428 |  0.988468 |   -0.57668 |    0.81697 |           inf | 41.4066 | 2.20303 |\n",
              "|  4 |     526 | 0.37037  | 0.367284 | 0.515432 | 0.589506 |         14.35 |           0 |            15.3 |             0 |           16.85 |             0 |           15.75 |             0 |            17.2 |             0 |            0 |            0 |            1 |            0 |            0 |            0 |           1 | -2.44929e-16 |  0.151428 |  0.988468 |   -0.57668 |    0.81697 |           inf | 41.3891 | 2.18349 |"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submission_preparator = Pipeline([\n",
        "    ('weather_merge', weather_merge_transformer(weather_df=weather_prepped)),  # weather_merge transformer already includes the creation of the datetime column'\n",
        "    ('extra_time_info', FunctionTransformer(func=extra_time_info)),\n",
        "    ('hour_selector', hour_selector_transformer(hour_list=[i for i in range(24)])),\n",
        "    ('time_normalization', time_norm_transformer(columns=['month', 'day', 'hour'])),\n",
        "    ('station_loc', station_loc_transformer(id_lat_lon=final_loc)),\n",
        "    ('station_id_dropper', station_id_dropper())\n",
        "])\n",
        "\n",
        "data_2_predict_prepared = submission_preparator.fit_transform(data_2_predict)\n",
        "\n",
        "Markdown(data_2_predict_prepared.head().to_markdown())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2d4WkBlCPfe"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "min_max = MinMaxScaler()\n",
        "standard = StandardScaler()\n",
        "\n",
        "numerical_variables = ['index', 'lat', 'lon', 'temperature-4', 'mm_precip-4', 'temperature-3', 'mm_precip-3', \n",
        "       'temperature-2', 'mm_precip-2', 'temperature-1', 'mm_precip-1', \n",
        "       'temperature', 'mm_precip']\n",
        "\n",
        "total_columns = ['index', 'year_normed', 'cos_month', 'sin_month', 'cos_day', 'sin_day', 'cos_hour', 'sin_hour', 'is_weekend', 'timeframe1',\n",
        "       'timeframe2', 'timeframe3', 'timeframe4', 'timeframe5', 'lat', 'lon', \n",
        "       'temperature-4', 'mm_precip-4', 'ctx-4', 'temperature-3', 'mm_precip-3', 'ctx-3', \n",
        "       'temperature-2', 'mm_precip-2', 'ctx-2', 'temperature-1', 'mm_precip-1', 'ctx-1', \n",
        "       'temperature', 'mm_precip', 'percentage']\n",
        "\n",
        "scaling_pipeline = ColumnTransformer([\n",
        "    ('min_max', min_max, numerical_variables),\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hwo-vuOE6e3C",
        "outputId": "2ebbf9eb-b52f-4eac-9948-524b98cccff6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14873854"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data_prepared)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['index', 'lat', 'lon', 'year', 'ctx-4', 'ctx-3', 'ctx-2', 'ctx-1',\n",
              "       'percentage', 'datetime', 'temperature', 'mm_precip', 'temperature-1',\n",
              "       'mm_precip-1', 'temperature-2', 'mm_precip-2', 'temperature-3',\n",
              "       'mm_precip-3', 'temperature-4', 'mm_precip-4', 'is_weekend',\n",
              "       'timeframe1', 'timeframe2', 'timeframe3', 'timeframe4', 'timeframe5',\n",
              "       'cos_month', 'sin_month', 'cos_day', 'sin_day', 'cos_hour', 'sin_hour',\n",
              "       'year_normed'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_prepared.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6sxLkIHC6e3D"
      },
      "outputs": [],
      "source": [
        "data_prepared = data_prepared[['index', 'year_normed', 'cos_month', 'sin_month', 'cos_day', 'sin_day', 'cos_hour', 'sin_hour', 'is_weekend', 'timeframe1',\n",
        "       'timeframe2', 'timeframe3', 'timeframe4', 'timeframe5', 'lat', 'lon', \n",
        "       'temperature-4', 'mm_precip-4', 'ctx-4', 'temperature-3', 'mm_precip-3', 'ctx-3', \n",
        "       'temperature-2', 'mm_precip-2', 'ctx-2', 'temperature-1', 'mm_precip-1', 'ctx-1', \n",
        "       'temperature', 'mm_precip', 'percentage']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "guWfHunR6e3D",
        "outputId": "2ad73b02-4561-48d7-983b-a012feaec0ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "╒════╤═════════╤═══════════════╤═════════════╤═════════════╤═══════════╤═══════════╤════════════╤════════════╤══════════════╤══════════════╤══════════════╤══════════════╤══════════════╤══════════════╤═════════╤═════════╤═════════════════╤═══════════════╤══════════╤═════════════════╤═══════════════╤═══════════╤═════════════════╤═══════════════╤══════════╤═════════════════╤═══════════════╤══════════╤═══════════════╤═════════════╤══════════════╕\n",
            "│    │   index │   year_normed │   cos_month │   sin_month │   cos_day │   sin_day │   cos_hour │   sin_hour │   is_weekend │   timeframe1 │   timeframe2 │   timeframe3 │   timeframe4 │   timeframe5 │     lat │     lon │   temperature-4 │   mm_precip-4 │    ctx-4 │   temperature-3 │   mm_precip-3 │     ctx-3 │   temperature-2 │   mm_precip-2 │    ctx-2 │   temperature-1 │   mm_precip-1 │    ctx-1 │   temperature │   mm_precip │   percentage │\n",
            "╞════╪═════════╪═══════════════╪═════════════╪═════════════╪═══════════╪═══════════╪════════════╪════════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════╪═════════╪═════════════════╪═══════════════╪══════════╪═════════════════╪═══════════════╪═══════════╪═════════════════╪═══════════════╪══════════╪═════════════════╪═══════════════╪══════════╪═══════════════╪═════════════╪══════════════╡\n",
            "│ 19 │       3 │          0.25 │         0.5 │    0.866025 │  0.688967 │  0.724793 │   0.460065 │   0.887885 │            0 │            1 │            0 │            0 │            0 │            0 │ 41.4035 │ 2.19366 │            15.7 │             0 │ 0.89899  │           14.35 │             0 │ 0.831909  │            14.6 │             0 │ 0.777778 │            15.4 │             0 │ 0.777778 │         16.65 │           0 │     0.777778 │\n",
            "├────┼─────────┼───────────────┼─────────────┼─────────────┼───────────┼───────────┼────────────┼────────────┼──────────────┼──────────────┼──────────────┼──────────────┼──────────────┼──────────────┼─────────┼─────────┼─────────────────┼───────────────┼──────────┼─────────────────┼───────────────┼───────────┼─────────────────┼───────────────┼──────────┼─────────────────┼───────────────┼──────────┼───────────────┼─────────────┼──────────────┤\n",
            "│ 20 │    7560 │          0.25 │         0.5 │    0.866025 │  0.688967 │  0.724793 │   0.460065 │   0.887885 │            0 │            1 │            0 │            0 │            0 │            0 │ 41.3958 │ 2.17871 │            15.7 │             0 │ 0        │           14.35 │             0 │ 0.0384615 │            14.6 │             0 │ 0.03125  │            15.4 │             0 │ 0.03125  │         16.65 │           0 │     0.03125  │\n",
            "├────┼─────────┼───────────────┼─────────────┼─────────────┼───────────┼───────────┼────────────┼────────────┼──────────────┼──────────────┼──────────────┼──────────────┼──────────────┼──────────────┼─────────┼─────────┼─────────────────┼───────────────┼──────────┼─────────────────┼───────────────┼───────────┼─────────────────┼───────────────┼──────────┼─────────────────┼───────────────┼──────────┼───────────────┼─────────────┼──────────────┤\n",
            "│ 21 │   53954 │          0.25 │         0.5 │    0.866025 │  0.688967 │  0.724793 │   0.460065 │   0.887885 │            0 │            1 │            0 │            0 │            0 │            0 │ 41.3653 │ 2.13314 │            15.7 │             0 │ 0.502841 │           14.35 │             0 │ 0.454327  │            14.6 │             0 │ 0.4375   │            15.4 │             0 │ 0.619792 │         16.65 │           0 │     0.71875  │\n",
            "├────┼─────────┼───────────────┼─────────────┼─────────────┼───────────┼───────────┼────────────┼────────────┼──────────────┼──────────────┼──────────────┼──────────────┼──────────────┼──────────────┼─────────┼─────────┼─────────────────┼───────────────┼──────────┼─────────────────┼───────────────┼───────────┼─────────────────┼───────────────┼──────────┼─────────────────┼───────────────┼──────────┼───────────────┼─────────────┼──────────────┤\n",
            "│ 22 │   70278 │          0.25 │         0.5 │    0.866025 │  0.688967 │  0.724793 │   0.460065 │   0.887885 │            0 │            1 │            0 │            0 │            0 │            0 │ 41.3756 │ 2.1439  │            15.7 │             0 │ 0.465035 │           14.35 │             0 │ 0.41716   │            14.6 │             0 │ 0.384615 │            15.4 │             0 │ 0.384615 │         16.65 │           0 │     0.349359 │\n",
            "├────┼─────────┼───────────────┼─────────────┼─────────────┼───────────┼───────────┼────────────┼────────────┼──────────────┼──────────────┼──────────────┼──────────────┼──────────────┼──────────────┼─────────┼─────────┼─────────────────┼───────────────┼──────────┼─────────────────┼───────────────┼───────────┼─────────────────┼───────────────┼──────────┼─────────────────┼───────────────┼──────────┼───────────────┼─────────────┼──────────────┤\n",
            "│ 23 │  162377 │          0.25 │         0.5 │    0.866025 │  0.688967 │  0.724793 │   0.460065 │   0.887885 │            0 │            1 │            0 │            0 │            0 │            0 │ 41.3875 │ 2.12371 │            15.7 │             0 │ 0.851852 │           14.35 │             0 │ 0.851852  │            14.6 │             0 │ 0.851852 │            15.4 │             0 │ 0.851852 │         16.65 │           0 │     0.851852 │\n",
            "╘════╧═════════╧═══════════════╧═════════════╧═════════════╧═══════════╧═══════════╧════════════╧════════════╧══════════════╧══════════════╧══════════════╧══════════════╧══════════════╧══════════════╧═════════╧═════════╧═════════════════╧═══════════════╧══════════╧═════════════════╧═══════════════╧═══════════╧═════════════════╧═══════════════╧══════════╧═════════════════╧═══════════════╧══════════╧═══════════════╧═════════════╧══════════════╛\n"
          ]
        }
      ],
      "source": [
        "print(data_prepared.head().to_markdown(tablefmt = 'fancy_grid'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM07uC4l6e3E"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "reduced_data_prepared = data_prepared.head(1000)\n",
        "\n",
        "reduced_data_prepared = reduced_data_prepared[reduced_data_prepared['hour'].isin([4,9,14,19,23])]\n",
        "\n",
        "X = reduced_data_prepared.drop(['percentage'], axis=1)\n",
        "y = reduced_data_prepared['percentage']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0n69xbBg6e3E",
        "outputId": "fe9887fc-0401-4472-80b7-431cea624342"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 729 candidates, totalling 2187 fits\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3,\n",
              "             estimator=XGBRegressor(base_score=None, booster=None,\n",
              "                                    callbacks=None, colsample_bylevel=None,\n",
              "                                    colsample_bynode=None,\n",
              "                                    colsample_bytree=None,\n",
              "                                    early_stopping_rounds=None,\n",
              "                                    enable_categorical=False, eval_metric=None,\n",
              "                                    feature_types=None, gamma=None, gpu_id=None,\n",
              "                                    grow_policy=None, importance_type=None,\n",
              "                                    interaction_constraints=None,\n",
              "                                    learning_rate=None, m...\n",
              "                                    min_child_weight=None, missing=nan,\n",
              "                                    monotone_constraints=None, n_estimators=100,\n",
              "                                    n_jobs=None, num_parallel_tree=None,\n",
              "                                    predictor=None, random_state=69, ...),\n",
              "             param_grid={'learning_rate': [0.1, 0.01, 0.001],\n",
              "                         'max_depth': [3, 5, 7],\n",
              "                         'n_estimators': [100, 200, 300],\n",
              "                         'reg_alpha': [0, 0.1, 1.0],\n",
              "                         'reg_lambda': [0.1, 1.0, 10.0],\n",
              "                         'subsample': [0.8, 0.9, 1.0]},\n",
              "             scoring='neg_mean_squared_error', verbose=1)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "\n",
        "space = {\n",
        "    'learning_rate': [0.1, 0.01, 0.001],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'reg_lambda': [0.1, 1.0, 10.0],\n",
        "    'reg_alpha': [0, 0.1, 1.0],\n",
        "    'n_estimators': [100, 200, 300]\n",
        "}\n",
        "\n",
        "xgb_model = XGBRegressor(objective='reg:squarederror', random_state = 69)\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=space, scoring='neg_mean_squared_error', cv=3, verbose=1)\n",
        "grid_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbtiaQn_6e3E"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "parameter = open('models/xgboost1000.json.json', 'w+')\n",
        "parameter.write(json.dumps(grid_search.best_params_))\n",
        "parameter.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41IPvSht6e3E"
      },
      "outputs": [],
      "source": [
        "xgb_model = XGBRegressor(objective='reg:squarederror', n_estimators=1000, max_depth=6, learning_rate=0.1, subsample=0.8, colsample_bytree=0.8, gamma=0.1, reg_alpha=0.1, reg_lambda=0.1, n_jobs=-1, random_state=123)\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print(f'RMSE: {rmse}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OWHeU1co6e3F"
      },
      "source": [
        "# BILSTM trials\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PLcHCoq6e3F",
        "outputId": "040b094b-b26b-4d96-850f-2d0b4fc7230a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ptbad\\anaconda3\\lib\\site-packages\\dask\\array\\core.py:1701: FutureWarning: The `numpy.column_stack` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\ptbad\\anaconda3\\lib\\site-packages\\dask\\array\\core.py:1701: FutureWarning: The `numpy.column_stack` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\ptbad\\anaconda3\\lib\\site-packages\\dask\\array\\core.py:1701: FutureWarning: The `numpy.column_stack` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\ptbad\\anaconda3\\lib\\site-packages\\dask\\array\\core.py:1701: FutureWarning: The `numpy.column_stack` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "# Assuming your dataframe is named 'df'\n",
        "# Extract the static data, the target and the time series data in seperate arrays\n",
        "\n",
        "static_data = data_prepared[['year', 'month', 'day', 'hour', 'is_weekend', 'timeframe1','timeframe2', 'timeframe3', 'timeframe4', 'lat', 'lon', 'temperature', 'mm_precip']].values\n",
        "\n",
        "timestep_1 = data_prepared[['temperature-1', 'mm_precip-1', 'ctx-1']].values\n",
        "timestep_2 = data_prepared[['temperature-2', 'mm_precip-2', 'ctx-2']].values\n",
        "timestep_3 = data_prepared[['temperature-3', 'mm_precip-3', 'ctx-3']].values\n",
        "timestep_4 = data_prepared[['temperature-4', 'mm_precip-4', 'ctx-4']].values\n",
        "\n",
        "time_series_data = np.stack((timestep_4, timestep_3, timestep_2, timestep_1), axis=1)\n",
        "\n",
        "target = data_prepared[['percentage']].values\n",
        "# timestep_1 = np.column_stack((data_prepared[['temperature-1', 'mm_precip-1', 'ctx-1']].values, static_data))\n",
        "# timestep_2 = np.column_stack((data_prepared[['temperature-2', 'mm_precip-2', 'ctx-2']].values, static_data))\n",
        "# timestep_3 = np.column_stack((data_prepared[['temperature-3', 'mm_precip-3', 'ctx-3']].values, static_data))\n",
        "# timestep_4 = np.column_stack((data_prepared[['temperature-4', 'mm_precip-4', 'ctx-4']].values, static_data))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pb4ZoKNN6e3G",
        "outputId": "f3120414-a63a-4b4c-ef4c-6e69dbed3557"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " ts_input (InputLayer)          [(None, 4, 3)]       0           []                               \n",
            "                                                                                                  \n",
            " static_input (InputLayer)      [(None, 13)]         0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 32)           4608        ['ts_input[0][0]']               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 32)           448         ['static_input[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 64)           0           ['lstm[0][0]',                   \n",
            "                                                                  'dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            65          ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import LSTM, Dense, Input, concatenate, Dropout\n",
        "\n",
        "ts_input = tf.keras.Input(shape=(4, 3), name='ts_input')\n",
        "static_input = tf.keras.Input(shape = (13,), name='static_input')\n",
        "LSTMout = LSTM(32, activation='relu', return_sequences=False)(ts_input)\n",
        "dropout_lstm = Dropout(0.2)(LSTMout)\n",
        "static_out = Dense(32, activation='relu')(static_input)\n",
        "dropout_static = Dropout(0.2)(static_out)\n",
        "\n",
        "merged_out = concatenate([LSTMout, static_out])\n",
        "merged_out = Dense(1, activation='relu')(merged_out)\n",
        "\n",
        "model = tf.keras.Model(inputs=[ts_input, static_input], outputs=merged_out)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
        "model.summary()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7jnaoyB66e3G"
      },
      "source": [
        "List of thing to do:\n",
        "1. Encode month/hour as cyclical features or simply remove them\n",
        "2. standarize percentages to max\n",
        "3. standarize temperatures and rain with min max scaler\n",
        "4. look into how to train with data from multiple hours and not just intervals of 4\n",
        "5. F******* TRAIN SOME MODELS \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
