{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>station_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>ctx-4</th>\n",
       "      <th>ctx-3</th>\n",
       "      <th>ctx-2</th>\n",
       "      <th>ctx-1</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>41.437338</td>\n",
       "      <td>2.174096</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.504902</td>\n",
       "      <td>0.751131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>271.0</td>\n",
       "      <td>41.450608</td>\n",
       "      <td>2.192363</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.753968</td>\n",
       "      <td>0.659341</td>\n",
       "      <td>0.645022</td>\n",
       "      <td>0.686508</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>149.0</td>\n",
       "      <td>41.395868</td>\n",
       "      <td>2.192952</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.491582</td>\n",
       "      <td>0.675214</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.801347</td>\n",
       "      <td>0.735043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>342.0</td>\n",
       "      <td>41.403497</td>\n",
       "      <td>2.193658</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.898990</td>\n",
       "      <td>0.831909</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>358.0</td>\n",
       "      <td>41.387244</td>\n",
       "      <td>2.179304</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.943333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  station_id        lat       lon    year  month   day  hour  \\\n",
       "0      0       290.0  41.437338  2.174096  2019.0    7.0  22.0   8.0   \n",
       "1      1       271.0  41.450608  2.192363  2022.0    6.0  10.0  21.0   \n",
       "2      2       149.0  41.395868  2.192952  2022.0    6.0   8.0  20.0   \n",
       "3      3       342.0  41.403497  2.193658  2020.0    2.0   4.0   4.0   \n",
       "4      4       358.0  41.387244  2.179304  2021.0    5.0  28.0   8.0   \n",
       "\n",
       "      ctx-4     ctx-3     ctx-2     ctx-1  percentage  \n",
       "0  0.352941  0.352941  0.352941  0.504902    0.751131  \n",
       "1  0.753968  0.659341  0.645022  0.686508    0.769231  \n",
       "2  0.491582  0.675214  0.864198  0.801347    0.735043  \n",
       "3  0.898990  0.831909  0.777778  0.777778    0.777778  \n",
       "4  0.480000  0.480000  0.513333  0.766667    0.943333  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "station_dataframe = dd.read_csv('data/data_bicing_joined_HX.csv', assume_missing=True, delimiter=';')\n",
    "\n",
    "weather_dataframe = dd.read_csv('weather_data/weather.csv', assume_missing=True, delimiter=',')\n",
    "\n",
    "station_dataframe = station_dataframe.loc[station_dataframe['status'] == 'IN_SERVICE']\n",
    "\n",
    "bare_df = station_dataframe[['station_id', 'lat', 'lon', 'year', 'month', 'day', 'hour', '% Docks Availlable',  '% Docks Available H-4','% Docks Available H-3', '% Docks Available H-2', '% Docks Available H-1']]\n",
    "bare_df = bare_df.rename(columns={'% Docks Availlable': 'percentage'})\n",
    "for i in range(1, 5):\n",
    "    bare_df = bare_df.rename(columns={f'% Docks Available H-{i}': f'ctx-{i}'})\n",
    "\n",
    "# Print the head of the updated DataFrame\n",
    "\n",
    "bare_df['index'] = bare_df.index\n",
    "bare_df = bare_df[['index', 'station_id', 'lat', 'lon', 'year', 'month', 'day', 'hour', 'ctx-4', 'ctx-3', 'ctx-2',\t'ctx-1', 'percentage']]\n",
    "\n",
    "bare_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>station_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>ctx-4</th>\n",
       "      <th>ctx-3</th>\n",
       "      <th>ctx-2</th>\n",
       "      <th>ctx-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>394</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.780864</td>\n",
       "      <td>0.799383</td>\n",
       "      <td>0.824074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>0.463768</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>0.532609</td>\n",
       "      <td>0.601449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>368</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.787037</td>\n",
       "      <td>0.709877</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.601852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>327</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>0.753472</td>\n",
       "      <td>0.809028</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.736111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>328</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.827160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  station_id  month  day  hour     ctx-4     ctx-3     ctx-2     ctx-1\n",
       "0      0         394      3    7     8  0.753086  0.780864  0.799383  0.824074\n",
       "1      1         337      3   23    12  0.463768  0.536232  0.532609  0.601449\n",
       "2      2         368      3   31     1  0.787037  0.709877  0.611111  0.601852\n",
       "3      3         327      3   23    15  0.753472  0.809028  0.819444  0.736111\n",
       "4      4         328      3    4    20  0.861111  0.802469  0.814815  0.827160"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2_predict = pd.read_csv('data\\metadata_sample_submission.csv', delimiter=',')\n",
    "\n",
    "data_2_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14877478"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bare_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_prep(weather_df:dd) -> dd:\n",
    "    \n",
    "    weather = weather_df.copy()\n",
    "\n",
    "    weather = weather.groupby(weather.index//2).mean()\n",
    "    \n",
    "    weather['mm_precip'] = weather['mm_precip']*2\n",
    "    weather['timestamp'] = (weather['timestamp']-900).astype(int)\n",
    "    weather['datetime'] = weather['timestamp'].map(lambda x: pd.to_datetime(x, unit='s'))\n",
    "\n",
    "    \n",
    "    weather['timestamp'] = weather['timestamp'].astype(int)\n",
    "\n",
    "    weather['datetime'] = weather['timestamp'].map(lambda x: pd.to_datetime(x, unit='s'))\n",
    "    \n",
    "    return weather\n",
    "\n",
    "def weather_merge(weather_df:dd, station_data:dd) -> dd:\n",
    "    weather = weather_df.copy()\n",
    "    stations = station_data.copy()\n",
    "\n",
    "    stations[['year', 'month', 'day', 'hour']] = stations[['year', 'month', 'day', 'hour']].astype(int)\n",
    "\n",
    "    stations['datetime'] = dd.to_datetime(stations['year'].astype(str) + '-' +\n",
    "                                                stations['month'].astype(str) + '-' +\n",
    "                                                stations['day'].astype(str) + ' ' +\n",
    "                                                stations['hour'].astype(str) + ':00:00')\n",
    "    \n",
    "    stations = dd.merge(left=stations, right=weather[['datetime', 'temperature','mm_precip']], left_on='datetime', right_on='datetime', how='left')\n",
    "\n",
    "    for i in range(1,5):\n",
    "        df_weather_shifted = weather.copy()\n",
    "        df_weather_shifted['datetime'] = df_weather_shifted['datetime'] + pd.Timedelta(hours=-i)\n",
    "        stations = stations.merge(df_weather_shifted[['datetime', 'temperature','mm_precip']], on='datetime', how='inner', suffixes=('', f'-{abs(i)}'))\n",
    "\n",
    "    return stations\n",
    "\n",
    "\n",
    "def extra_time_info(df:dd) -> dd:\n",
    "\n",
    "    def is_weekend(day_of_week):\n",
    "        return 1 if day_of_week >= 5 else 0\n",
    "\n",
    "    df['is_weekend'] = df['datetime'].dt.dayofweek.map(is_weekend, meta=('is_weekend', 'int64'))\n",
    "\n",
    "    df['timeframe1'] = df['datetime'].dt.hour.map(lambda x: 1 if x <= 4 else 0, meta=('timeframe1', 'int64'))\n",
    "    df['timeframe2'] = df['datetime'].dt.hour.map(lambda x: 1 if x >= 5 and x <=9 else 0, meta=('timeframe1', 'int64'))\n",
    "    df['timeframe3'] = df['datetime'].dt.hour.map(lambda x: 1 if x >= 10 and x <=14 else 0, meta=('timeframe1', 'int64'))\n",
    "    df['timeframe4'] = df['datetime'].dt.hour.map(lambda x: 1 if x >= 15 and x <=19 else 0, meta=('timeframe1', 'int64'))\n",
    "    df['timeframe5'] = df['datetime'].dt.hour.map(lambda x: 1 if x >= 20 else 0, meta=('timeframe1', 'int64'))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def station_loc(id_lat_lon:dd, df:dd) -> dd:\n",
    "\n",
    "    assert all(item in list(id_lat_lon.columns) for item in ['station_id', 'lat', 'lon']), 'id_lat_lon must contain station_id, lat and lon columns'\n",
    "    id_locator = id_lat_lon.copy()\n",
    "    data = df.copy()\n",
    "    id_locator = id_locator.drop_duplicates(subset=['station_id'])\n",
    "\n",
    "    data = data.merge(id_locator[['station_id', 'lat', 'lon']], on='station_id', how='left')\n",
    "    data = data.drop(['station_id'], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "def time_norm(df:dd, columns:list) -> dd:\n",
    "    \n",
    "        data = df.copy()\n",
    "        for col in columns:\n",
    "            data['cos_'+col] = np.cos(2*np.pi*data[col]/data[col].max())\n",
    "            data['sin_'+col] = np.sin(2*np.pi*data[col]/data[col].max())\n",
    "            data = data.drop([col], axis=1)\n",
    "            \n",
    "        return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|    |   index |   station_id |     lat |     lon |   year |   month |   day |   hour |     ctx-4 |     ctx-3 |     ctx-2 |     ctx-1 |   percentage |   temperature |   mm_precip |   temperature-1 |   mm_precip-1 |   temperature-2 |   mm_precip-2 |   temperature-3 |   mm_precip-3 |   temperature-4 |   mm_precip-4 |   is_weekend |   timeframe1 |   timeframe2 |   timeframe3 |   timeframe4 |   timeframe5 |\n",
       "|---:|--------:|-------------:|--------:|--------:|-------:|--------:|------:|-------:|----------:|----------:|----------:|----------:|-------------:|--------------:|------------:|----------------:|--------------:|----------------:|--------------:|----------------:|--------------:|----------------:|--------------:|-------------:|-------------:|-------------:|-------------:|-------------:|-------------:|\n",
       "|  0 |       0 |          290 | 41.4373 | 2.1741  |   2019 |       7 |    22 |      8 | 0.352941  | 0.352941  | 0.352941  | 0.504902  |     0.751131 |            31 |           0 |            31.7 |             0 |           32.35 |             0 |           32.35 |             0 |            32.2 |             0 |            0 |            0 |            1 |            0 |            0 |            0 |\n",
       "|  1 |   36224 |           89 | 41.3879 | 2.15034 |   2019 |       7 |    22 |      8 | 0.62963   | 0.62963   | 0.636364  | 0.515432  |     0.247863 |            31 |           0 |            31.7 |             0 |           32.35 |             0 |           32.35 |             0 |            32.2 |             0 |            0 |            0 |            1 |            0 |            0 |            0 |\n",
       "|  2 |   39987 |          279 | 41.4159 | 2.17456 |   2019 |       7 |    22 |      8 | 0.37037   | 0.37037   | 0.424242  | 0.58642   |     0.965812 |            31 |           0 |            31.7 |             0 |           32.35 |             0 |           32.35 |             0 |            32.2 |             0 |            0 |            0 |            1 |            0 |            0 |            0 |\n",
       "|  3 |  145251 |          228 | 41.4068 | 2.15584 |   2019 |       7 |    22 |      8 | 0.0952381 | 0.0952381 | 0.134199  | 0.424603  |     0.923077 |            31 |           0 |            31.7 |             0 |           32.35 |             0 |           32.35 |             0 |            32.2 |             0 |            0 |            0 |            1 |            0 |            0 |            0 |\n",
       "|  4 |  161934 |          325 | 41.395  | 2.13028 |   2019 |       7 |    22 |      8 | 0.0869565 | 0.0869565 | 0.0869565 | 0.0869565 |     0.160535 |            31 |           0 |            31.7 |             0 |           32.35 |             0 |           32.35 |             0 |            32.2 |             0 |            0 |            0 |            1 |            0 |            0 |            0 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_prepped = weather_prep(weather_dataframe)\n",
    "\n",
    "data_prepared = weather_merge(weather_prepped, bare_df)\n",
    "\n",
    "data_prepared = extra_time_info(data_prepared)\n",
    "\n",
    "data_prepared = data_prepared.drop(['datetime'], axis=1)\n",
    "\n",
    "# locations = station_dataframe[['station_id', 'lat', 'lon']]\n",
    "\n",
    "# data_prepared = station_loc(id_lat_lon=locations, df=data_prepared)\n",
    "\n",
    "Markdown(data_prepared.head().to_markdown())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14873854"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prepared = data_prepared[['year', 'month', 'day', 'hour', 'is_weekend', 'timeframe1',\n",
    "       'timeframe2', 'timeframe3', 'timeframe4', 'timeframe5', 'lat', 'lon', \n",
    "       'temperature-4', 'mm_precip-4', 'ctx-4', 'temperature-3', 'mm_precip-3', 'ctx-3', \n",
    "       'temperature-2', 'mm_precip-2', 'ctx-2', 'temperature-1', 'mm_precip-1', 'ctx-1', \n",
    "       'temperature', 'mm_precip', 'percentage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401881392"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════╤════════╤═════════╤═══════╤════════╤══════════════╤══════════════╤══════════════╤══════════════╤══════════════╤═════════╤═════════╤═════════════════╤═══════════════╤══════════╤═════════════════╤═══════════════╤══════════╤═════════════════╤═══════════════╤══════════╤═════════════════╤═══════════════╤══════════╤═══════════════╤═════════════╤══════════════╕\n",
      "│    │   year │   month │   day │   hour │   is_weekend │   timeframe1 │   timeframe2 │   timeframe3 │   timeframe4 │     lat │     lon │   temperature-4 │   mm_precip-4 │    ctx-4 │   temperature-3 │   mm_precip-3 │    ctx-3 │   temperature-2 │   mm_precip-2 │    ctx-2 │   temperature-1 │   mm_precip-1 │    ctx-1 │   temperature │   mm_precip │   percentage │\n",
      "╞════╪════════╪═════════╪═══════╪════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════╪═════════╪═════════════════╪═══════════════╪══════════╪═════════════════╪═══════════════╪══════════╪═════════════════╪═══════════════╪══════════╪═════════════════╪═══════════════╪══════════╪═══════════════╪═════════════╪══════════════╡\n",
      "│  0 │   2019 │       7 │    22 │      8 │            0 │            0 │            0 │            0 │            0 │ 41.4373 │ 2.1741  │           32.2  │             0 │ 0.352941 │           32.35 │             0 │ 0.352941 │           32.35 │             0 │ 0.352941 │            31.7 │             0 │ 0.504902 │         31    │           0 │     0.751131 │\n",
      "├────┼────────┼─────────┼───────┼────────┼──────────────┼──────────────┼──────────────┼──────────────┼──────────────┼─────────┼─────────┼─────────────────┼───────────────┼──────────┼─────────────────┼───────────────┼──────────┼─────────────────┼───────────────┼──────────┼─────────────────┼───────────────┼──────────┼───────────────┼─────────────┼──────────────┤\n",
      "│  1 │   2022 │       6 │    10 │     21 │            0 │            0 │            1 │            0 │            0 │ 41.4506 │ 2.19236 │           19.8  │             0 │ 0.753968 │           19.85 │             0 │ 0.659341 │           20.5  │             0 │ 0.645022 │            21   │             0 │ 0.686508 │         21.05 │           0 │     0.769231 │\n",
      "├────┼────────┼─────────┼───────┼────────┼──────────────┼──────────────┼──────────────┼──────────────┼──────────────┼─────────┼─────────┼─────────────────┼───────────────┼──────────┼─────────────────┼───────────────┼──────────┼─────────────────┼───────────────┼──────────┼─────────────────┼───────────────┼──────────┼───────────────┼─────────────┼──────────────┤\n",
      "│  2 │   2022 │       6 │     8 │     20 │            0 │            0 │            1 │            0 │            0 │ 41.3959 │ 2.19295 │           20.05 │             0 │ 0.491582 │           20.05 │             0 │ 0.675214 │           20.05 │             0 │ 0.864198 │            20.3 │             0 │ 0.801347 │         20.75 │           0 │     0.735043 │\n",
      "├────┼────────┼─────────┼───────┼────────┼──────────────┼──────────────┼──────────────┼──────────────┼──────────────┼─────────┼─────────┼─────────────────┼───────────────┼──────────┼─────────────────┼───────────────┼──────────┼─────────────────┼───────────────┼──────────┼─────────────────┼───────────────┼──────────┼───────────────┼─────────────┼──────────────┤\n",
      "│  3 │   2020 │       2 │     4 │      4 │            0 │            1 │            0 │            0 │            0 │ 41.4035 │ 2.19366 │           15.7  │             0 │ 0.89899  │           14.35 │             0 │ 0.831909 │           14.6  │             0 │ 0.777778 │            15.4 │             0 │ 0.777778 │         16.65 │           0 │     0.777778 │\n",
      "├────┼────────┼─────────┼───────┼────────┼──────────────┼──────────────┼──────────────┼──────────────┼──────────────┼─────────┼─────────┼─────────────────┼───────────────┼──────────┼─────────────────┼───────────────┼──────────┼─────────────────┼───────────────┼──────────┼─────────────────┼───────────────┼──────────┼───────────────┼─────────────┼──────────────┤\n",
      "│  4 │   2021 │       5 │    28 │      8 │            0 │            0 │            0 │            0 │            0 │ 41.3872 │ 2.1793  │           24.4  │             0 │ 0.48     │           24.35 │             0 │ 0.48     │           24.65 │             0 │ 0.513333 │            24.1 │             0 │ 0.766667 │         23.95 │           0 │     0.943333 │\n",
      "╘════╧════════╧═════════╧═══════╧════════╧══════════════╧══════════════╧══════════════╧══════════════╧══════════════╧═════════╧═════════╧═════════════════╧═══════════════╧══════════╧═════════════════╧═══════════════╧══════════╧═════════════════╧═══════════════╧══════════╧═════════════════╧═══════════════╧══════════╧═══════════════╧═════════════╧══════════════╛\n"
     ]
    }
   ],
   "source": [
    "print(data_prepared.head().to_markdown(tablefmt = 'fancy_grid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "reduced_data_prepared = data_prepared.head(1000)\n",
    "\n",
    "reduced_data_prepared = reduced_data_prepared[reduced_data_prepared['hour'].isin([4,9,14,19,23])]\n",
    "\n",
    "X = reduced_data_prepared.drop(['percentage'], axis=1)\n",
    "y = reduced_data_prepared['percentage']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 729 candidates, totalling 2187 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=69, ...),\n",
       "             param_grid={'learning_rate': [0.1, 0.01, 0.001],\n",
       "                         'max_depth': [3, 5, 7],\n",
       "                         'n_estimators': [100, 200, 300],\n",
       "                         'reg_alpha': [0, 0.1, 1.0],\n",
       "                         'reg_lambda': [0.1, 1.0, 10.0],\n",
       "                         'subsample': [0.8, 0.9, 1.0]},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "space = {\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'reg_lambda': [0.1, 1.0, 10.0],\n",
    "    'reg_alpha': [0, 0.1, 1.0],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "xgb_model = XGBRegressor(objective='reg:squarederror', random_state = 69)\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=space, scoring='neg_mean_squared_error', cv=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "parameter = open('models/xgboost1000.json.json', 'w+')\n",
    "parameter.write(json.dumps(grid_search.best_params_))\n",
    "parameter.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(objective='reg:squarederror', n_estimators=1000, max_depth=6, learning_rate=0.1, subsample=0.8, colsample_bytree=0.8, gamma=0.1, reg_alpha=0.1, reg_lambda=0.1, n_jobs=-1, random_state=123)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BILSTM trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ptbad\\anaconda3\\lib\\site-packages\\dask\\array\\core.py:1701: FutureWarning: The `numpy.column_stack` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ptbad\\anaconda3\\lib\\site-packages\\dask\\array\\core.py:1701: FutureWarning: The `numpy.column_stack` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ptbad\\anaconda3\\lib\\site-packages\\dask\\array\\core.py:1701: FutureWarning: The `numpy.column_stack` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ptbad\\anaconda3\\lib\\site-packages\\dask\\array\\core.py:1701: FutureWarning: The `numpy.column_stack` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# Assuming your dataframe is named 'df'\n",
    "# Extract the static data, the target and the time series data in seperate arrays\n",
    "\n",
    "static_data = data_prepared[['year', 'month', 'day', 'hour', 'is_weekend', 'timeframe1','timeframe2', 'timeframe3', 'timeframe4', 'lat', 'lon', 'temperature', 'mm_precip']].values\n",
    "\n",
    "timestep_1 = data_prepared[['temperature-1', 'mm_precip-1', 'ctx-1']].values\n",
    "timestep_2 = data_prepared[['temperature-2', 'mm_precip-2', 'ctx-2']].values\n",
    "timestep_3 = data_prepared[['temperature-3', 'mm_precip-3', 'ctx-3']].values\n",
    "timestep_4 = data_prepared[['temperature-4', 'mm_precip-4', 'ctx-4']].values\n",
    "\n",
    "time_series_data = np.stack((timestep_4, timestep_3, timestep_2, timestep_1), axis=1)\n",
    "\n",
    "target = data_prepared[['percentage']].values\n",
    "# timestep_1 = np.column_stack((data_prepared[['temperature-1', 'mm_precip-1', 'ctx-1']].values, static_data))\n",
    "# timestep_2 = np.column_stack((data_prepared[['temperature-2', 'mm_precip-2', 'ctx-2']].values, static_data))\n",
    "# timestep_3 = np.column_stack((data_prepared[['temperature-3', 'mm_precip-3', 'ctx-3']].values, static_data))\n",
    "# timestep_4 = np.column_stack((data_prepared[['temperature-4', 'mm_precip-4', 'ctx-4']].values, static_data))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " ts_input (InputLayer)          [(None, 4, 3)]       0           []                               \n",
      "                                                                                                  \n",
      " static_input (InputLayer)      [(None, 13)]         0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 32)           4608        ['ts_input[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           448         ['static_input[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 64)           0           ['lstm[0][0]',                   \n",
      "                                                                  'dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            65          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,121\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import LSTM, Dense, Input, concatenate, Dropout\n",
    "\n",
    "ts_input = tf.keras.Input(shape=(4, 3), name='ts_input')\n",
    "static_input = tf.keras.Input(shape = (13,), name='static_input')\n",
    "LSTMout = LSTM(32, activation='relu', return_sequences=False)(ts_input)\n",
    "dropout_lstm = Dropout(0.2)(LSTMout)\n",
    "static_out = Dense(32, activation='relu')(static_input)\n",
    "dropout_static = Dropout(0.2)(static_out)\n",
    "\n",
    "merged_out = concatenate([LSTMout, static_out])\n",
    "merged_out = Dense(1, activation='relu')(merged_out)\n",
    "\n",
    "model = tf.keras.Model(inputs=[ts_input, static_input], outputs=merged_out)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of thing to do:\n",
    "1. Encode month/hour as cyclical features or simply remove them\n",
    "2. standarize percentages to max\n",
    "3. standarize temperatures and rain with min max scaler\n",
    "4. look into how to train with data from multiple hours and not just intervals of 4\n",
    "5. F******* TRAIN SOME MODELS \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
